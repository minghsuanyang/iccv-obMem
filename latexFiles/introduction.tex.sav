Consider the image and it's corresponding objects in Figure \ref{fig:introPhoto}. Even though the person on the right is comparable in size to the left person, he is remembered far less by humans (indicated by their memorability scores of $0.18$ and $0.64$ respectively). People tend to remember the fish in the center and the person on the left, even after $30$ minutes have passed (memorability score $= 0.64$). Interestingly, despite vibrant colors and considerable size, the boat is also remembered far less by humans (memorability $= 0.18$).

While recent studies related to image memorability \cite{isola11}, \cite{khosla12}, \cite{isola14}, \cite{zoya15}, \cite{kim13}  have shed light on what distinguishes the memorability of different images and the intrinsic and extrinsic properties that make those images memorable, the above example raises an interesting question: what exactly about an image is remembered? Despite progress in the computer vision literature on image memorability, a clear understanding of the memorability of the specific components of an image is still unknown. For example, the memorability of complex images may be principally driven by it's most memorable object, or alternatively, by a combination of particular objects. Furthermore, not all objects in an image will be equally remembered by people and as the example in figure \ref{fig:introPhoto} seems to suggest, there exists significant and interesting differences in memorability of objects in an image. Can specific objects inside images be memorable to all us and how can we better understand what makes those objects more memorable?

\begin{figure}[t]
\centering
\subfigure{\centering \includegraphics[width=0.4\textwidth]{figures/introduction/113.jpg}}

\vspace{-3mm}

\subfigure{\centering \includegraphics[width=0.4\textwidth]{figures/introduction/allObs.png}}
\vspace{-5mm}\caption{\footnotesize\textbf{Memorability of different objects.} Memorability scores of objects for the image in the top row obtained from our pysophysics experiment. }\label{fig:introPhoto}
\end{figure}

%Need to highlight why this will be important to study for a computer vision standpoint and memorability literature viewpoint. Maybe point that image memorability is an interesting problem, can be predicted by comp vis algos, has applicability such as modfying of photographs based on memorability. 

In this paper, we systematically explore the memorability of objects within individual images and shed light on the various factors and properties that drive object memorability by augmenting both the images and object segmentations in the 850 existing images from PASCAL 2010 \cite{pascal10} dataset with memorability scores and class labels. By exploring the connection between object memorability, saliency, and image memorability, our paper makes several important contributions. 

Firstly, we show that just like image memorability, object memorability is a property that is shared across subjects and objects remembered by one person are also likely to be remembered by others and vice versa. Secondly, we show that there exists a strong correlation between visual saliency and object memorability and demonstrate insights when can visual saliency directly predict object memorability and when does it fail to do so. While there have been have a few studies that explore the connection between image memorability and visual saliency \cite{zoya15}, \cite{lemeur13}, our work is the first to explore the connection between object memorability and visual saliency. Third, we explore the connection between image memorability and object memorability and show that if the maximum object memorability is a strong predictor if an image is highly memorable or forgetabble. 

Lastly, our dataset can serve as a benchmark to evaluate future memorability map predictions algorithms and as shown in the section 4, we evaluate the performance of state-of-the-art saliency models and baseline models built on 


In this paper, we explore the connection between fixation
prediction and salient object segmentation by augmenting
850 existing images from PASCAL 2010 [12] dataset with
eye fixations, and salient object segmentation labeling. In
Sec. 3 we argue that by making the image acquisition and
image annotation independent to each other, we can avoid
dataset design bias – a specific type of bias that is caused
by experimenters’ unnatural selection of dataset images.
With fixations and salient object labels simultaneously
presented in the same set of images, we report a series
of interesting findings. 

First, we show that salient object
segmentation is a valid problem because of the high consistency
among labelers. Second, unlike fixation datasets,
the most widely used salient object segmentation dataset is
heavily biased. As a result, all top performing algorithms
for salient object segmentation have poor generalization
power when they are tested on more realistic images. Finally,
we demonstrate that there exists a strong correlation
between fixations and salient objects.

Inspired by these discoveries, in Sec. 4 we propose a
new model of salient object segmentation. By combining
existing fixation-based saliency models with segmentation
techniques, our model bridges the gap between fixation
prediction and salient object segmentation. Despite its
simplicity, this model significantly outperforms state-of-
4321 the-arts salient object segmentation algorithms on all 3
salient object datasets.

%Studying these questions, might not only help understand image and object memorability in more detail, but it can also have important contributions to computer vision. For example, understanding which regions and objects in an image are memorable would enable us to modify the memorability of images which can have applications in adversting etc.

 here, we are not just interested in understanding image memorability, we are interested in understanding memorability of objects in an image. Can some objects in individual images be more memorable to us and can we estimate their predictability?  And how exactly do different objects matter, whether it be size, spatial arrangement, etc.


%http://cvcl.mit.edu/papers/IsolaXiaoTorralbaOliva-PredictingImageMemory-CVPR2011.pdf​ ​ In summary, in this paper, a large dataset of images is released wherein the authors ran experiments on human subjects and quantified how memorable each image is. They also ran various analysis on what makes an image more memorable than others. For example, aesthetically pleasing images like landscapes etc are less memorable than an image containing a person. Subsequently, they have showed using computer vision algorithms that they can predict the memorability of images automatically with high accuracy.
%
%http://web.mit.edu/jxiao/Public/publication/2012/NIPSmemorability/paper.pdf​ is a follow up work done by the same authors and is related to memorability of regions in an image i.e. some regions in an image will be more memorable than others. If you go to Figure 4 (pg 7), the authors have built 'memorability maps' for each image via computer vision algorithms. Basically this means that for every pixel (and consequently a region) in an image, their algorithm outputs a memorability value. They then used these memorability maps to predict image memorability from the dataset in the first paper with even greater accuracy. Do note that they have not collected any actual ground truth memorability maps i.e. we still don't know what regions/objects humans consider more memorable in an image.

